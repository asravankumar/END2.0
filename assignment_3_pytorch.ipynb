{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_3_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODvbtYPe5bI3VKnqVLZYPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asravankumar/END2.0/blob/master/assignment_3_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XQyS4oqfsql"
      },
      "source": [
        "**Import the Essentials**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGp1tAVSpCrj"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnfvENKHf1HT"
      },
      "source": [
        "**Download Training MNIST Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2fvQsy47Uqb"
      },
      "source": [
        "# download training mnist dataset which consists of 60000 labelled images\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root='./data'\n",
        "    ,train=True\n",
        "    ,download=True\n",
        "    ,transform=transforms.Compose([\n",
        "        transforms.ToTensor() # converts the images into pytorch tensors\n",
        "    ])\n",
        ")"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT9n1rgTfhWT"
      },
      "source": [
        "**Data Set Creation**\n",
        "\n",
        "Create custom MNIST Adder dataset which consists of mnist images + random number as input and the correct image label and sum as output.\n",
        "\n",
        "The random number is a one-hot encoding vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RpuILleVERv"
      },
      "source": [
        "# data set creation\n",
        "class MNISTAdderDataset(Dataset):\n",
        "  # Dataset to create mnist custom data for mnist + random number adder.\n",
        "\n",
        "  def __init__(self, dataset):\n",
        "    self.mnist_data = dataset\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    # returns tuple with following input and output for every image.\n",
        "    # input : x1 - tensor image\n",
        "    # input : x2 - one hot vector for random number\n",
        "    # labelled output : y1 - the image's label number.\n",
        "    # labelled output : y2 - the sum.\n",
        "\n",
        "    x1, y1 = self.mnist_data[index]\n",
        "    x2 = random.randint(0,9)\n",
        "    y2 = y1 + x2 \n",
        "    return (x1, F.one_hot(torch.tensor(x2), 10).float(), y1, y2)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.mnist_data)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-qcXejjh48S"
      },
      "source": [
        "**Data Loader with batch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCca1ac9Y01I"
      },
      "source": [
        "mnist_adder_training_data = MNISTAdderDataset(train_set)\n",
        "mnist_adder_training_data_loader = torch.utils.data.DataLoader(mnist_adder_training_data,\n",
        "                                               batch_size=100,\n",
        "                                               shuffle=False,\n",
        "                                               )"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoXsauYgY4zB",
        "outputId": "28030509-ac20-498f-de7b-b302ba7fc7ad"
      },
      "source": [
        "next(iter(mnist_adder_training_data_loader))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
              " tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]),\n",
              " tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
              "         1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
              "         9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n",
              "         1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n",
              "         7, 8, 3, 1]),\n",
              " tensor([ 8,  7,  5,  9, 18,  6,  1,  7, 10,  9, 11,  6,  9, 10,  7,  9, 10, 12,\n",
              "         15, 10,  8,  4, 18,  1,  9,  5, 12,  3, 11, 12,  9,  8,  8, 10,  5,  5,\n",
              "         15,  1,  8,  6,  3,  9, 16, 12,  6, 14, 11, 12, 14,  4,  4,  6, 11,  7,\n",
              "          9, 16,  4, 10,  7,  3, 12, 13, 11,  1,  8,  5, 11,  2,  6,  8,  2, 15,\n",
              "          1,  9,  9,  2,  2,  7,  4, 13, 14,  5,  8, 14, 16,  9,  6, 11,  6,  7,\n",
              "         10,  8,  6,  6, 11,  0, 12, 11, 11,  9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaxSgI4liDhL"
      },
      "source": [
        "**Visualizing sample data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "i79MWiJuZL9v",
        "outputId": "51b9ad64-491e-4687-da63-2c49ca65b429"
      },
      "source": [
        "x1, x2, y1, y2 = next(iter(mnist_adder_training_data))\n",
        "plt.imshow(x1.squeeze(), cmap='gray')\n",
        "print('label', y1)\n",
        "print('random number hot vector', x2)\n",
        "print('sum', y1)\n",
        "print(x1.shape)\n"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label 5\n",
            "random number hot vector tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "sum 5\n",
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph87E9moiQy-"
      },
      "source": [
        "**Network Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ubgnbO_hG1p"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Network creation\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # input is 28x28 with 1 channel, kernel size is 5x5\n",
        "        # output of convolution layer is 24x24 i.e (28 - 5 )/ 1 + 1\n",
        "        # maxpool layer is with kernel size 2 and stride 2\n",
        "        # output of max pool layer is 12x12 i.e (24 - 2)/2 + 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "\n",
        "        # input is 12x12 with 1 channel, kernel size is 5x5\n",
        "        # output of convolution layer is 8x8 i.e (12 - 5 )/ 1 + 1\n",
        "        # maxpool layer is with kernel size 2 and stride 2\n",
        "        # output of max pool layer is 4x4 i.e (8 - 2)/2 + 1\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "        # fully connected layer with input will be 12 * 4 * 4\n",
        "        # and 50 output features\n",
        "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=50)\n",
        "        # another fully connected layer\n",
        "        self.fc2 = nn.Linear(in_features=50, out_features=40)\n",
        "        # output layer for image classification\n",
        "        self.out = nn.Linear(in_features=40, out_features=10)\n",
        "\n",
        "        # fully connected layer after combining image classification output and random number one-hot vector.\n",
        "        self.fc3 = nn.Linear(in_features=20, out_features=21)\n",
        "        #self.fc4 = nn.Linear(in_features=30, out_features=24)\n",
        "\n",
        "        # final sum output layer. 19 features output. 19 because of one-hot vector for 0 to 19. as sum of 0 - 9 image  with 0 - 9 random numbers.\n",
        "         self.out2 = nn.Linear(in_features=21, out_features=19)\n",
        "\n",
        "    def forward(self, t, rand_num_vector):\n",
        "        # convolution layer\n",
        "        t = self.conv1(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "        # convolution layer\n",
        "        t = self.conv2(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "        \n",
        "        # hidden linear layer\n",
        "        # converting the image to a straight vector.\n",
        "        t = t.reshape(-1, 12 * 4 * 4)\n",
        "        t = self.fc1(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        # hidden linear layer\n",
        "        t = self.fc2(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        # output layer for image classification\n",
        "        t = self.out(t)\n",
        "        \n",
        "        # converting to one hot vector for image predicted value.\n",
        "        t_vector = F.one_hot(t.argmax(dim=1), num_classes=10)\n",
        "        #print(\"t_vector\", t_vector)\n",
        "        #print(\"rand_num_vector\", rand_num_vector)\n",
        "\n",
        "        # now combining the image output with random number vector for addition.\n",
        "        combined_vector = torch.cat([t_vector, rand_num_vector], dim=-1)\n",
        "        #print(\"combined vector\", combined_vector)\n",
        "        combined_vector = self.fc3(combined_vector)\n",
        "        combined_vector = F.relu(combined_vector)\n",
        "\n",
        "        #combined_vector = self.fc4(combined_vector)\n",
        "        #combined_vector = F.relu(combined_vector)\n",
        "\n",
        "\n",
        "        # final layer with outputs the sum of the two numbers.\n",
        "        combined_vector = self.out2(combined_vector)\n",
        "        combined_vector = F.relu(combined_vector)\n",
        "\n",
        "        return t, combined_vector"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h9cH-GWkW9-"
      },
      "source": [
        "**Network Details**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADmX1j_Vz-O5",
        "outputId": "a1d5327c-4f04-4318-9552-ab89e24951ca"
      },
      "source": [
        "network = Network()\n",
        "network"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=192, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=40, bias=True)\n",
              "  (out): Linear(in_features=40, out_features=10, bias=True)\n",
              "  (fc3): Linear(in_features=20, out_features=24, bias=True)\n",
              "  (out2): Linear(in_features=24, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mwqGYJ5kclw"
      },
      "source": [
        "**Checking the predicted value in the network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIhs2SflEPDG",
        "outputId": "cd8a22eb-693b-40d1-cc35-6dfb073434a1"
      },
      "source": [
        "x1, x2, y1, y2 = next(iter(mnist_adder_training_data))\n",
        "print('y1:', y1)\n",
        "print('x2:', x2)\n",
        "print('y2:', y2)\n",
        "\n",
        "network = Network()\n",
        "pred_y1, pred_y2 = network(x1.unsqueeze(0), x2.unsqueeze(0))\n",
        "\n",
        "print('Predicted Image :', pred_y1.argmax(dim=1))\n",
        "print('Predicted Sum :', pred_y2.argmax(dim=1))\n"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y1: 5\n",
            "x2: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
            "y2: 12\n",
            "Predicted Image : tensor([9])\n",
            "Predicted Sum : tensor([5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFkH6WWkkkQg"
      },
      "source": [
        "**Training the Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNt_IzDvGEHr",
        "outputId": "e7bacf46-fc91-4952-8449-4e00da9671ce"
      },
      "source": [
        "import torch.optim as optim\n",
        "torch.set_grad_enabled(True) # to enable the gradients.\n",
        "\n",
        "network = Network()\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.02) # using adam's optimizer with learning rate of 0.02\n",
        "\n",
        "# to check the number of correct predictions.\n",
        "def get_num_correct(X, Y):\n",
        "  return X.argmax(dim=1).eq(Y).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct_mnist = 0\n",
        "    total_correct_sum = 0\n",
        "\n",
        "    for batch in mnist_adder_training_data_loader:\n",
        "        # for every batch predict using network and backpropagate the loss.\n",
        "        # x1s : images input\n",
        "        # x2s : random number one hot vectors.\n",
        "        # y1s : image labels.\n",
        "        # y2s : sum.\n",
        "    \n",
        "        x1s, x2s, y1s, y2s = batch\n",
        "        x2s = x2s.squeeze()\n",
        "\n",
        "        # predictions\n",
        "        predicted_y1s, predicted_y2s = network(x1s, x2s)\n",
        "\n",
        "        # calculate the loss for image prediction.\n",
        "        loss1 = F.cross_entropy(predicted_y1s, y1s)\n",
        "        # calculate the loss for sum.\n",
        "        loss2 = F.cross_entropy(predicted_y2s, y2s)\n",
        "        loss = loss1 + loss2 # total loss.\n",
        "\n",
        "        optimizer.zero_grad()           \n",
        "        loss.backward()                 # calculate gradients\n",
        "        optimizer.step()                # update weights \n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct_mnist += get_num_correct(predicted_y1s, y1s)\n",
        "        total_correct_sum += get_num_correct(predicted_y2s, y2s)\n",
        "        #break\n",
        "    #break\n",
        "    image_accuracy = (total_correct_mnist/60000.0)*100;\n",
        "    image_sum = (total_correct_sum/60000.0)*100;\n",
        "\n",
        "    print(\n",
        "        \"epoch:\", epoch,\n",
        "        \"batch_size: \", 100,\n",
        "        \"correct_images_count\", total_correct_mnist,\n",
        "        \"correct_sum_count\", total_correct_sum,\n",
        "        \"image_accuracy\",image_accuracy, \n",
        "        \"sum_accuracy\", image_sum,\n",
        "        \"total_loss\", total_loss\n",
        "    )"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 batch_size:  100 correct_images_count 54612 correct_sum_count 38350 image_accuracy 91.02 sum_accuracy 63.916666666666664 total_loss 968.1364297270775\n",
            "epoch: 1 batch_size:  100 correct_images_count 57231 correct_sum_count 43314 image_accuracy 95.38499999999999 sum_accuracy 72.19 total_loss 692.24047935009\n",
            "epoch: 2 batch_size:  100 correct_images_count 57431 correct_sum_count 43342 image_accuracy 95.71833333333333 sum_accuracy 72.23666666666666 total_loss 678.8417452573776\n",
            "epoch: 3 batch_size:  100 correct_images_count 57670 correct_sum_count 43670 image_accuracy 96.11666666666666 sum_accuracy 72.78333333333333 total_loss 660.866904437542\n",
            "epoch: 4 batch_size:  100 correct_images_count 57632 correct_sum_count 43569 image_accuracy 96.05333333333334 sum_accuracy 72.615 total_loss 666.2280558943748\n",
            "epoch: 5 batch_size:  100 correct_images_count 57715 correct_sum_count 43771 image_accuracy 96.19166666666666 sum_accuracy 72.95166666666667 total_loss 656.60302901268\n",
            "epoch: 6 batch_size:  100 correct_images_count 57567 correct_sum_count 43582 image_accuracy 95.94500000000001 sum_accuracy 72.63666666666667 total_loss 675.5272351503372\n",
            "epoch: 7 batch_size:  100 correct_images_count 57889 correct_sum_count 43887 image_accuracy 96.48166666666667 sum_accuracy 73.14500000000001 total_loss 648.0555792152882\n",
            "epoch: 8 batch_size:  100 correct_images_count 57799 correct_sum_count 43722 image_accuracy 96.33166666666668 sum_accuracy 72.87 total_loss 659.6569232940674\n",
            "epoch: 9 batch_size:  100 correct_images_count 57940 correct_sum_count 43852 image_accuracy 96.56666666666666 sum_accuracy 73.08666666666667 total_loss 646.2071326375008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IEkiqc7luyg"
      },
      "source": [
        "**Testing the Network & Model**\n",
        "\n",
        "Download test MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQuobIDBWTAA"
      },
      "source": [
        "# download test mnist data which consists of 10000 images.\n",
        "\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root='./data'\n",
        "    ,train=False\n",
        "    ,download=True\n",
        "    ,transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n",
        "# test data loaders\n",
        "mnist_adder_test_data = MNISTAdderDataset(test_set)\n",
        "mnist_adder_test_data_loader = torch.utils.data.DataLoader(mnist_adder_test_data,\n",
        "                                               batch_size=100,\n",
        "                                               shuffle=False,\n",
        "                                               )"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv8sbNPPl_ZR"
      },
      "source": [
        "**Model Accuracy with test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Mwedr7XGlF",
        "outputId": "b33c4ae3-1124-43cf-a40e-f6601410dbfe"
      },
      "source": [
        "total_image_correct = 0\n",
        "total_sum_correct = 0\n",
        "\n",
        "for batch in mnist_adder_test_data_loader:\n",
        "  x1s, x2s, y1s, y2s = batch\n",
        "  predicted_y1s, predicted_y2s = network(x1s, x2s)\n",
        "  total_image_correct += get_num_correct(predicted_y1s, y1s)\n",
        "  total_sum_correct += get_num_correct(predicted_y2s, y2s)\n",
        "\n",
        "print(\"total_image_correct\", total_image_correct, \"image prediction accuracy:\", (total_image_correct/10000.0) * 100)\n",
        "print(\"total_sum_correct\", total_sum_correct, \"sum prediction accuracy\", (total_sum_correct/10000) * 100)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_image_correct 9625 image prediction accuracy: 96.25\n",
            "total_sum_correct 7217 sum prediction accuracy 72.17\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}