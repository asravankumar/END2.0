{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkAXpIUcz6XVZIxwRJuo+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asravankumar/END2.0/blob/master/session_5/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSN-GE0Tlvjn"
      },
      "source": [
        "**Data Loaders to Download, Preprocess & Create Training/Validation DataSet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEY044CemMv_"
      },
      "source": [
        "The data is a set of Rotten Tomatoes Movie Reviews labelled and provided readily by stanford.\n",
        "The raw data is available in two formats\n",
        "- raw csv files.\n",
        "- Penn Treebank(PTB tree) format.\n",
        "\n",
        "The raw csv files contains list of files which consists of list of \n",
        "- sentences\n",
        "- phrases\n",
        "- trees mapping sentences and phrases\n",
        "- sentiment of each phrase.\n",
        "\n",
        "The PTB format consists of the sentences, and the respective phrases in tree format.\n",
        "\n",
        "In order to get the sentiment of each sentences, we need to parse the tree structure. [pytreebank](https://github.com/JonathanRaiman/pytreebank)  does the job effectively.\n",
        "\n",
        "We download the sentences and sentiments from [pytreebank](https://github.com/JonathanRaiman/pytreebank) and build models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xNM-ccomBta"
      },
      "source": [
        "**Data Download to CSV File**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJhHXyNrl_8-",
        "outputId": "4d26588f-1aa2-4733-ad17-ad48d235f72e"
      },
      "source": [
        "!pip install pytreebank"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytreebank\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
            "Building wheels for collected packages: pytreebank\n",
            "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp37-none-any.whl size=37070 sha256=6120444dc2b77cffd686549d60fe43368592d0b31aff78dae0d3a8a62131098a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
            "Successfully built pytreebank\n",
            "Installing collected packages: pytreebank\n",
            "Successfully installed pytreebank-0.2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADwCehGTuKSr"
      },
      "source": [
        "Stanford Sentiment Treebank Data splits into train, dev and test sets. We therefore maintain the split as given by them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLJZ1RqpuExM"
      },
      "source": [
        "import pytreebank\n",
        "dataset = pytreebank.load_sst()\n",
        "\n",
        "for category in ['train', 'test', 'dev']:\n",
        "  out_file = open('sentences_{}.txt'.format(category), 'w')\n",
        "  out_file.write('{}\\t{}\\n'.format(\"sentence\", \"labels\"))\n",
        "  for item in dataset[category]:\n",
        "    label, sentence = item.to_labeled_lines()[0]\n",
        "    out_file.write(\"{}\\t{}\\n\".format(sentence, label))\n",
        "  out_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud3glq4DvTiv"
      },
      "source": [
        "import pandas as pd\n",
        "# create training and validation pandas dataframes from downloaded data.\n",
        "\n",
        "train_df = pd.read_csv('sentences_train.txt', delimiter='\\t')\n",
        "valid_df = pd.read_csv('sentences_dev.txt', delimiter='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV9RdHPxw0VS",
        "outputId": "a65cd7ff-03b6-4d5c-eab5-d07a75c143f3"
      },
      "source": [
        "print(\"training df shape\", train_df.shape)\n",
        "print(\"validation df shape\", valid_df.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training df shape (8544, 2)\n",
            "validation df shape (1101, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j2HpnNFyjn1"
      },
      "source": [
        "**Understanding our Dataset**\n",
        "\n",
        "We plot a bar graph on our training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "xiZnixtuw_IR",
        "outputId": "956e3925-a806-4d73-fe31-aec914839110"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = train_df['labels'].value_counts(sort=False).plot(kind='bar')\n",
        "ax.set_xlabel(\"labels\")\n",
        "ax.set_ylabel(\"number of samples in training dataset\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'number of samples in training dataset')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEDCAYAAADEAyg+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYRElEQVR4nO3dfbRddX3n8ffH8KQoIAWZCIRgjbZYESGCOowFrcqDiqig2BFkpMyqIKhdjlg7xefBtlqL06pMiaIVHBQtqVJoiqJjUctDEQRlSBUGIoKKEjAKJHznj72vOcZ779kkOefs5L5fa511zv7tffb5nrPgfvN7TlUhSdJsHjbpACRJ/WeykCQNZbKQJA1lspAkDWWykCQNZbKQJA21xaQDGIWddtqpFi5cOOkwJGmTctVVV/2oqnae7txmmSwWLlzIlVdeOekwJGmTkuSWmc7ZDCVJGspkIUkaymQhSRrKZCFJGspkIUkaymQhSRrKZCFJGspkIUkaarOclCdp9Bae9oVJhwDAzWccPukQ5gRrFpKkoUwWkqShTBaSpKGGJoskR3UpkyRtvrrULN7SsUyStJmacTRUkkOBw4Bdk5w5cGo7YPWoA5Mk9cdsQ2e/D1wJvAi4aqD8HuANowxKktQvMyaLqvom8M0k57bXLaiqG8cWmSSpN7r0WRwCXANcDJBknyRLRxqVJKlXuszgfhuwP3AZQFVdk2TPEcaknnGmrqQuNYsHqurudcpqFMFIkvqpS83i+iSvBOYlWQScAlw+2rAkSX3SpWbxOuBJwH3AecBK4PWjDEqS1C9DaxZVtQp4K/DWJPOAbavqFyOPTJLUG12W+zg3yXZJtgWuA25I8qbRhyZJ6osuzVB7VdVK4MXAPwJ7Aq8aaVSSpF7pkiy2TLIlTbJYWlUP4GgoSZpTuiSLjwA3A9sCX0myB00ntyRpjujSwX0mMLiQ4C1JDh5dSJKkvum0B3eSw2mGz24zUPyOkUQkSeqdLqOhPgy8nGa+RYCjgD1GHJckqUe69Fk8s6qOBX5SVW8HngE8YbRhSZL6pEuy+Hn7vCrJY4EHgPmjC0mS1Ddd+iw+n2QH4M+Bq2mGzf7tSKOSJPVKl5rFn1XVT6vqApq+it8C3jXsTUl2T/KlJDckuT7JqW35jkmWJbmpfX50W54kZyZZnuTaJPsO3Ou49vqbkhy3fl9VkrS+uiSLr029qKr72uXKvzbL9VNWA39UVXsBTwdOSrIXcBpwaVUtAi5tjwEOBRa1jxOBD0GTXIDTgQNo9tU4fSrBSJLGY8ZmqCT/AdgVeHiSp9KMhALYDnjEsBtX1e3A7e3re5J8u73fEcBB7WXn0Gyq9Oa2/ONVVcDXk+yQZH577bKququNaxnN7n3nPZQvKklaf7P1WTwfeDWwG/D+gfJ7gD9+KB+SZCHwVOAbwC5tIgH4AbBL+3pX4NaBt93Wls1ULkkakxmTRVWdA5yT5KVtf8V6SfJI4ALg9VW1Mskvz1VVJdko60wlOZGm+YoFCxZsjFtKklpdlvu4YLoZ3FU1dAZ3uwDhBcAnq+qzbfEdSeZX1e1tM9OdbfkKYPeBt+/Wlq1gbbPVVPll08R5FnAWwOLFi13oUJI2opHN4E5ThTgb+HZVDTZjLQWmRjQdB1w4UH5sOyrq6cDdbXPVJcDzkjy67dh+XlsmSRqTLvMsnllVeye5tqrenuR9NPtaDPMfafa9uC7JNW3ZHwNnAOcneQ1wC3B0e+4i4DBgObAKOB6gqu5K8k7giva6d0x1dkuSxqNLslh3BveP6TCDu6q+ytoRVOt6zjTXF3DSDPdaAizpEKskaQScwS1JGqpLB/c725cXJPk8sE07MU+SNEfMNinvJbOcY2B0kyRpMzdbzeKF7fNjgGcCX2yPDwYuB0wWkjRHzDYp73iAJP8E7DU167qdG/GxsUQnSeqFLgsJ7j6wPAfAHYBTpCVpDukyGurSJJewduG+lwP/PLqQJEl902U01MlJjgSe1RadVVWfG21YkqQ+6VKzoE0OJghJmqO69FlIkuY4k4UkaSiThSRpqKF9Fkmuo1kPatDdwJXAu6rqx6MITJLUH106uP8RWAOc2x6/gmYP7h/QTM574fRvkyRtLroki9+rqn0Hjq9LcnVV7ZvkP48qMElSf3Tps5iXZP+pgyRPA+a1h6tHEpUkqVe61CxOAJYkeSTNZkYrgROSbAv8j1EGJ0nqhy4zuK8Anpxk+/Z4cC+L80cVmCSpP7qMhtoaeCmwENgiaXZKrap3jDQySVJvdGmGupBmqOxVwH2jDUeS1EddksVuVXXIyCORJPVWl9FQlyd58sgjkST1VpeaxYHAq5N8j6YZKkBV1d4jjUyS1BtdksWhI49CktRrMyaLJNtV1UrgnjHGI0nqodlqFucCL6AZBVU0zU9TCnjcCOOSJPXIjMmiql7QPu85vnAkSX3UaVvVJLsCewxeX1VfGVVQkqR+6TKD+73Ay4EbaJYqh6YZymQhSXNEl5rFi4EnVpWztzXnLTztC5MOAYCbzzh80iFojukyKe+7wJajDkSS1F9dahargGuSXMrA2lBVdcrIopIk9UqXZLG0fUiS5qgu+1mcM45AJEn9NdsM7vOr6ugk19GMfvoVrg0lSXPHbDWLU9vnF4wjEElSf804Gqqqbm+fb5nuMezGSZYkuTPJtwbK3pZkRZJr2sdhA+fekmR5khuTPH+g/JC2bHmS09b/q0qS1tfQobNJnp7kiiT3Jrk/yZokKzvc+2PAdJsm/WVV7dM+Lmo/Yy/gFcCT2vf8TZJ5SeYBf02z8u1ewDHttZKkMeoyz+J/AscANwEPB06g+QM+q3Y5kLs6xnEE8Kmquq+qvgcsB/ZvH8ur6rtVdT/wqfZaSdIYdUkWVNVyYF5VramqjzJ9jaGrk5Nc2zZTPbot2xW4deCa29qymcolSWPUJVmsSrIVzcS8P0vyho7vm86HgN8E9gFuB963nvf5NUlOTHJlkit/+MMfbqzbSpLo9kf/Ve11JwM/A3YHXro+H1ZVd7S1kweB/0XTzASwor3vlN3aspnKp7v3WVW1uKoW77zzzusTniRpBrMmi7aD+T1V9YuqWllVb6+qN7bNUg9ZkvkDh0cCUyOllgKvSLJ1kj2BRcC/AlcAi5Ls2dZuXoGzySVp7GadwV1Va5LskWSrtoO5syTnAQcBOyW5DTgdOCjJPjST/G4G/mv7OdcnOZ9mGfTVwElVtaa9z8nAJcA8YElVXf9Q4pAkbbgua0N9F/iXJEtpmqEAqKr3z/amqjpmmuKzZ7n+3cC7pym/CLioQ5ySpBHpkiz+vX08DHhUW/Zry39IkjZfXZLFDVX16cGCJEeNKB5JUg91GQ31lo5lkqTN1Gyrzh4KHAbsmuTMgVPb0XRCS5LmiNmaob4PXAm8CLhqoPwe4A2jDEqS1C8zJouq+ibwzSTnVtUDY4xJktQzQ/ssTBSSpPVd40mSNIeYLCRJQw2dZ5HkCcCbgD0Gr6+qZ48wLklSj3SZlPdp4MM0q8SuGW04kqQ+6pIsVlfVh0YeiSSpt7r0WfxDktcmmZ9kx6nHyCOTJPVGl5rFce3zmwbKCnjcxg9HktRHQ5NFVe05jkAkaVO18LQvTDoEAG4+4/CR3Xu2taGeXVVfTPKS6c5X1WdHFpUkqVdmq1n8LvBF4IXTnCvAZCFJc8Rsa0Od3j4fP75wJEl95AxuSdJQJgtJ0lAmC0nSUEOTRZKjkjyqff0nST6bZN/RhyZJ6osuNYv/XlX3JDkQ+D3gbMDlPyRpDumSLKYWDzwcOKuqvgBsNbqQJEl90yVZrEjyEeDlwEVJtu74PknSZqLLH/2jgUuA51fVT4Ed+dV1oiRJm7kue3CvAu4EDmyLVgM3jTIoSVK/dBkNdTrwZuAtbdGWwN+NMihJUr90aYY6EngR8DOAqvo+8KhRBiVJ6pcuyeL+qiqaxQNJsu1oQ5Ik9U2XZHF+OxpqhyR/APwzzX7ckqQ5osvmR3+R5LnASuCJwJ9W1bKRRzZhc2EzE0nqqsu2qrTJYbNPEJKk6c22U949tP0U654Cqqq2G1lUkqRemW3zI0c8SZKAjst2JNk3ySlJXpfkqR3fsyTJnUm+NVC2Y5JlSW5qnx/dlifJmUmWJ7l2cFXbJMe119+U5LiH+gUlSRuuy6S8PwXOAX4D2An4WJI/6XDvjwGHrFN2GnBpVS0CLm2PAQ4FFrWPE2lXtU2yI3A6cACwP3D6VIKRJI1Pl5rF7wNPq6rT2325nw68atibquorwF3rFB9Bk3hon188UP7xanydZpjufOD5wLKququqfkLTyb5uApIkjViXZPF9YJuB462BFev5ebtU1e3t6x8Au7SvdwVuHbjutrZspnJJ0hh1GTp7N3B9kmU0o6OeC/xrkjMBquqU9fngqqok0422Wi9JTqRpwmLBggUb67aSJLoli8+1jymXbcDn3ZFkflXd3jYz3dmWrwB2H7hut7ZsBXDQOuXTfn5VnQWcBbB48eKNloQkSd1mcJ8z7JqHYClwHHBG+3zhQPnJST5F05l9d5tQLgHeM9Cp/TzWrn4rSRqTockiyQuAdwJ7tNd3mpSX5DyaWsFOSW6jGdV0Bs1aU68BbqHZWAngIuAwYDmwCjie5kPuSvJO4Ir2undU1bqd5pKkEevSDPUB4CXAde3qs51U1TEznHrONNcWcNIM91kCLOn6uZKkja/LaKhbgW89lEQhSdq8dKlZ/DfgoiRfBu6bKqyq948sKklSr3RJFu8G7qWZa7HVaMORJPVRl2Tx2Kr6nZFHIknqrS59Fhcled7II5Ek9VaXZPGHwMVJfp5kZZJ7kqwcdWCSpP7oMinPfS0kaY7rtK1qO4N6EQMLCrarykqS5oAuM7hPAE6lWZfpGpolyr8GPHu0oUmS+qJLn8WpwNOAW6rqYOCpwE9HGpUkqVe6JItfVNUvAJJsXVXfAZ442rAkSX3Spc/itiQ7AH8PLEvyE5pFACVJc0SX0VBHti/fluRLwPbAxSONSpLUK0OboZL8ZpKtpw6BhcAjRhmUJKlfuvRZXACsSfJ4mp3odgfOHWlUkqRe6ZIsHqyq1cCRwAer6k3A/NGGJUnqky7J4oEkx9Bsg/r5tmzL0YUkSeqbLsnieOAZwLur6ntJ9gQ+MdqwJEl90mU01A3AKQPH3wPeO8qgJEn90qVmIUma40wWkqShZkwWST7RPp86vnAkSX00W81ivySPBf5Lkkcn2XHwMa4AJUmTN1sH94eBS4HHAVfRzN6eUm25JGkOmLFmUVVnVtVvA0uq6nFVtefAw0QhSXNIl6Gzf5jkKcB/aou+UlXXjjYsSVKfdFlI8BTgk8Bj2scnk7xu1IFJkvqjy34WJwAHVNXPAJK8l2Zb1Q+OMjBJUn90mWcRYM3A8Rp+tbNbkrSZ61Kz+CjwjSSfa49fDJw9upAkSX3TpYP7/UkuAw5si46vqn8baVSSpF7pUrOgqq4Grh5xLJKknnJtKEnSUCYLSdJQsyaLJPOSfGlcwUiS+mnWZFFVa4AHk2w/pngkST3UpYP7XuC6JMuAn00VVtUpM79ldkluBu6hmbOxuqoWtyvZ/m9gIXAzcHRV/SRJgL8CDgNWAa9uO9wlSWPSJVl8tn1sbAdX1Y8Gjk8DLq2qM5Kc1h6/GTgUWNQ+DgA+1D5LksakyzyLc5I8HFhQVTeOMJYjgIPa1+cAl9EkiyOAj1dVAV9PskOS+VV1+whjkSQN6LKQ4AuBa4CL2+N9kizdwM8t4J+SXJXkxLZsl4EE8ANgl/b1rsCtA++9rS2TJI1Jl2aotwH70/xLn6q6JsmG7mdxYFWtSPIYYFmS7wyerKpKUg/lhm3SORFgwYIFGxieJGlQl3kWD1TV3euUPbghH1pVK9rnO4HP0SSjO5LMB2if72wvXwHsPvD23dqyde95VlUtrqrFO++884aEJ0laR5dkcX2SVwLzkixK8kHg8vX9wCTbJnnU1GvgecC3gKXAce1lxwEXtq+XAsem8XTgbvsrJGm8ujRDvQ54K3AfcB5wCfDODfjMXYDPNSNi2QI4t6ouTnIFcH6S1wC3AEe3119EM2x2Oc3Q2eM34LMlSeuhy2ioVcBb202Pqqru2ZAPrKrvAk+ZpvzHwHOmKS/gpA35TEnShukyGuppSa4DrqWZnPfNJPuNPjRJUl90aYY6G3htVf0fgCQH0myItPcoA5Mk9UeXDu41U4kCoKq+CqweXUiSpL6ZsWaRZN/25ZeTfISmc7uAl9POuZAkzQ2zNUO9b53j0wdeP6QJc5KkTduMyaKqDh5nIJKk/hrawZ1kB+BYmqXDf3n9hixRLknatHQZDXUR8HXgOjZwmQ9J0qapS7LYpqreOPJIJEm91WXo7CeS/EGS+Ul2nHqMPDJJUm90qVncD/w5zfpQU6OgCtjQZcolSZuILsnij4DHr7MFqiRpDunSDDW12qskaY7qUrP4GXBNki/RLFMOOHRWkuaSLsni79uHJGmO6rKfxTnjCESS1F9dZnB/j2nWgqoqR0NJ0hzRpRlq8cDrbYCjAOdZSNIcMnQ0VFX9eOCxoqo+ABw+htgkST3RpRlq34HDh9HUNLrUSCRJm4kuf/QH97VYDdwMHD2SaCRJvdRlNJT7WkjSHNelGWpr4KX8+n4W7xhdWJKkPunSDHUhcDdwFQMzuCVJc0eXZLFbVR0y8kgkSb3VZSHBy5M8eeSRSJJ6q0vN4kDg1e1M7vuAAFVVe480MklSb3RJFoeOPApJUq91GTp7yzgCkST1V5c+C0nSHGeykCQNZbKQJA1lspAkDWWykCQNZbKQJA1lspAkDbXJJIskhyS5McnyJKdNOh5Jmks2iWSRZB7w1zSzyfcCjkmy12SjkqS5Y5NIFsD+wPKq+m5V3Q98CjhiwjFJ0pyRqpp0DEMleRlwSFWd0B6/Cjigqk4euOZE4MT28InAjWMP9NftBPxo0kH0hL/FWv4Wa/lbrNWH32KPqtp5uhNdFhLcJFTVWcBZk45jUJIrq2rxpOPoA3+Ltfwt1vK3WKvvv8Wm0gy1Ath94Hi3tkySNAabSrK4AliUZM8kWwGvAJZOOCZJmjM2iWaoqlqd5GTgEmAesKSqrp9wWF30qllswvwt1vK3WMvfYq1e/xabRAe3JGmyNpVmKEnSBJksJElDmSwkSUNtEh3cm4okv0Uzs3zXtmgFsLSqvj25qDRp7X8XuwLfqKp7B8oPqaqLJxfZ+CXZH6iquqJdsucQ4DtVddGEQ5uoJB+vqmMnHcds7ODeSJK8GTiGZimS29ri3WiG+X6qqs6YVGx9kuT4qvropOMYlySnACcB3wb2AU6tqgvbc1dX1b6TjG+ckpxOs77bFsAy4ADgS8BzgUuq6t0TDG9skqw77D/AwcAXAarqRWMPqgOTxUaS5P8CT6qqB9Yp3wq4vqoWTSayfkny/6pqwaTjGJck1wHPqKp7kywEPgN8oqr+Ksm/VdVTJxrgGLW/xT7A1sAPgN2qamWSh9PUuvaeaIBjkuRq4Abgb4GiSRbn0fzDkqr68uSim5nNUBvPg8BjgVvWKZ/fnpszklw70ylgl3HG0gMPm2p6qqqbkxwEfCbJHjS/x1yyuqrWAKuS/HtVrQSoqp8nmUv/jywGTgXeCrypqq5J8vO+JokpJouN5/XApUluAm5tyxYAjwdOnvFdm6ddgOcDP1mnPMDl4w9nou5Isk9VXQPQ1jBeACwBnjzZ0Mbu/iSPqKpVwH5ThUm2Zw79g6qqHgT+Msmn2+c72AT+Fvc+wE1FVV2c5Ak0y6kPdnBf0f5rai75PPDIqT+Qg5JcNv5wJupYYPVgQVWtBo5N8pHJhDQxz6qq++CXfzCnbAkcN5mQJqeqbgOOSnI4sHLS8Qxjn4UkaSjnWUiShjJZSJKGMllI6ynJvUPOL0zyrYd4z4+1O0NKvWKykCQNZbKQNlCSRya5NMnVSa5LcsTA6S2SfDLJt5N8Jskj2vfsl+TLSa5KckmS+dPc94wkNyS5NslfjO0LSdMwWUgb7hfAke3SHQcD70syNeHuicDfVNVv0wyPfG2SLYEPAi+rqv1o5lz8ylIXSX4DOJJmVYC9gXeN56tI03OehbThArwnybNoJpftytqZ6rdW1b+0r/8OOAW4GPgdYFmbU+YBt69zz7tpktDZST5PM3dFmhiThbThfh/YGdivqh5IcjOwTXtu3YlMU2sBXV9Vz5jphu1WwvsDzwFeRrMKwLM3duBSVzZDSRtue+DONlEcDOwxcG5Bkqmk8Ergq8CNwM5T5Um2TPKkwRsmeSSwfbt09xuAp4z6S0izsWYhbbhPAv/Qrqp6JfCdgXM3AiclWUKz0uiHqur+dnjsme26SFsAHwCuH3jfo4ALk2xDUxN54xi+hzQjl/uQJA1lM5QkaSiThSRpKJOFJGkok4UkaSiThSRpKJOFJGkok4UkaSiThSRpqP8PIp0I2h9zYaMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoXlcTlCzGrZ"
      },
      "source": [
        "We clearly can see there is an **imbalance** in the data w.r.t number of samples for each label. \n",
        "\n",
        "labels 1,2,3 have more samples than 0 and 4. \n",
        "\n",
        "We need to augment some data in labels 0 and 4 to balance them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zf8VrAWF32A"
      },
      "source": [
        "**Data Augmentation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1donL6lTkRB"
      },
      "source": [
        "**- Back Translate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af43JOl9LDqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a20cbe6-91e3-40b3-b9ac-605abc019f39"
      },
      "source": [
        "!pip install googletrans\n",
        "!pip install google_trans_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans\n",
            "  Downloading https://files.pythonhosted.org/packages/71/3a/3b19effdd4c03958b90f40fe01c93de6d5280e03843cc5adf6956bfc9512/googletrans-3.0.0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/50/606213e12fb49c5eb667df0936223dcaf461f94e215ea60244b2b1e9b039/hstspreload-2020.12.22-py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 20.2MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2020.12.5)\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-cp37-none-any.whl size=15737 sha256=4561a40fed6021b89ca9eac4dfd97bf96f5a7bf9ad0294d00cd234e39131b2af\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/1a/a7/eaf4d7a3417a0c65796c547cff4deb6d79c7d14c2abd29273e\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hstspreload, sniffio, rfc3986, h11, hyperframe, hpack, h2, httpcore, httpx, googletrans\n",
            "Successfully installed googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n",
            "Collecting google_trans_new\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/7b/9f136106dc5824dc98185c97991d3cd9b53e70a197154dd49f7b899128f6/google_trans_new-1.1.9-py3-none-any.whl\n",
            "Installing collected packages: google-trans-new\n",
            "Successfully installed google-trans-new-1.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRHwtzecW2T-"
      },
      "source": [
        "import random\n",
        "import googletrans, google_trans_new\n",
        "\n",
        "translator = google_trans_new.google_translator()\n",
        "\n",
        "def back_translate(sentence):\n",
        "  available_languages = list(googletrans.LANGUAGES.keys()) \n",
        "  selected_language = random.choice(available_languages) \n",
        "  translations = translator.translate(sentence, lang_tgt=selected_language) \n",
        "  back_translated_text = translator.translate(translations, lang_src=selected_language, lang_tgt='en') \n",
        "  return back_translated_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4lmYWV-BW5PX",
        "outputId": "b046901d-cb48-4bd0-f9de-c2045473d6e5"
      },
      "source": [
        "back_translate(\"training the model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Model training '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyvhdlwWXxPI"
      },
      "source": [
        "**- Random Swap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TutR7jvlX6GD"
      },
      "source": [
        "def random_swap(sentence, n=5): \n",
        "    length = range(len(sentence)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0dFNOiyX7aA",
        "outputId": "2bfc6c5b-38d4-4ee0-cc1f-843ff447f175"
      },
      "source": [
        "random_swap(\"training the model\".split(' '), 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['training', 'model', 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfEyVt0oYbh6"
      },
      "source": [
        "**- Random Deletion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUNFDGRfYTYk"
      },
      "source": [
        "def random_deletion(words, p=0.5): \n",
        "    if len(words) == 1: # return if single word\n",
        "        return words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
        "    if len(remaining) == 0: # if not left, sample a random word\n",
        "        return [random.choice(words)] \n",
        "    else:\n",
        "        return remaining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLeZecVTYgFF",
        "outputId": "10857fe1-edd2-4e7e-e90d-10724933b910"
      },
      "source": [
        "random_deletion(\"training the model\".split(' '), 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['training', 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap_fQ7FSaInX"
      },
      "source": [
        "We shall augment the datasets based on the above three techniques\n",
        "\n",
        "As we can see from the data, the labels 0 and 4 are less than that of others, we shall back translate few random samples and populate these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "khPDNfnSaH8j",
        "outputId": "4a935ece-9fbb-488d-da11-f46fd38cd361"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8539</th>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8540</th>\n",
              "      <td>No surprises .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8541</th>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8542</th>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8543</th>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8544 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  labels\n",
              "0     The Rock is destined to be the 21st Century 's...       3\n",
              "1     The gorgeously elaborate continuation of `` Th...       4\n",
              "2     Singer/composer Bryan Adams contributes a slew...       3\n",
              "3     You 'd think by now America would have had eno...       2\n",
              "4                  Yet the act is still charming here .       3\n",
              "...                                                 ...     ...\n",
              "8539                                    A real snooze .       0\n",
              "8540                                     No surprises .       1\n",
              "8541  We 've seen the hippie-turned-yuppie plot befo...       3\n",
              "8542  Her fans walked out muttering words like `` ho...       0\n",
              "8543                                In this case zero .       1\n",
              "\n",
              "[8544 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_Ttdq6glZEu",
        "outputId": "5a337c95-a215-4bc4-ea5a-6d4676adebc8"
      },
      "source": [
        "train_df.loc[7163]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence    Collapses after 30 minutes into a slap-happy s...\n",
              "labels                                                      0\n",
              "Name: 7163, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhbC1d19cPCb"
      },
      "source": [
        "def back_translate_sentences_based_on_label(label, new_sentences_count):\n",
        "  label_indexes = train_df[train_df['labels'] == label].index.tolist()\n",
        "  selected_indexes = random.sample(label_indexes, new_sentences_count)\n",
        "  new_label_sentences = []\n",
        "  for index in selected_indexes:\n",
        "    sentence = train_df.loc[index].sentence\n",
        "    back_translated_sentence = back_translate(sentence)\n",
        "    new_label_sentences.append([back_translated_sentence, label])\n",
        "  new_df = pd.DataFrame(new_label_sentences, columns=['sentence', 'labels'])\n",
        "  return(new_df)\n",
        "\n",
        "new_label_0_df = back_translate_sentences_based_on_label(0, 400)\n",
        "new_label_1_df = back_translate_sentences_based_on_label(4, 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RavP2UUHtQtw"
      },
      "source": [
        "new_augmented_train_df = pd.concat([train_df, new_label_0_df, new_label_1_df], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "563n_4kDvSg7",
        "outputId": "d8cde167-adf7-4eda-9568-aa1754119474"
      },
      "source": [
        "new_augmented_train_df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    2322\n",
              "1    2218\n",
              "2    1624\n",
              "0    1492\n",
              "4    1488\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbBYQuiQvjSU"
      },
      "source": [
        "Let's augment using random_swap on rest of the labels 1,2,3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bto4qyUcvuly"
      },
      "source": [
        "def random_swap_sentences_on_labels(temp_df, label, count):\n",
        "  label_indexes = temp_df[temp_df['labels'] == label].index.tolist()\n",
        "  selected_indexes = random.sample(label_indexes, count)\n",
        "  #print(\"selected_indexes\", selected_indexes)\n",
        "  for index in selected_indexes:\n",
        "    sentence = temp_df.loc[index].sentence\n",
        "    #print(\"index\", index, \"sentence\", sentence)\n",
        "    new_sentence = random_swap(sentence.split(' '), 2)\n",
        "    temp_df.loc[index].sentence = new_sentence\n",
        "  return(temp_df)\n",
        "\n",
        "temp_df = new_augmented_train_df.copy()\n",
        "temp_df = random_swap_sentences_on_labels(temp_df, 1, 100)\n",
        "temp_df = random_swap_sentences_on_labels(temp_df, 2, 100)\n",
        "temp_df = random_swap_sentences_on_labels(temp_df, 3, 150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC54wNz80epP"
      },
      "source": [
        "def random_delete_sentences_on_labels(temp_df, label, count):\n",
        "  label_indexes = temp_df[temp_df['labels'] == label].index.tolist()\n",
        "  selected_indexes = random.sample(label_indexes, count)\n",
        "  #print(\"selected_indexes\", selected_indexes)\n",
        "  for index in selected_indexes:\n",
        "    sentence = temp_df.loc[index].sentence\n",
        "    #print(\"index\", index, \"sentence\", sentence)\n",
        "    new_sentence = random_deletion(sentence.split(' '), 2)\n",
        "    temp_df.loc[index].sentence = new_sentence\n",
        "  return(temp_df)\n",
        "\n",
        "temp_df = temp_df.copy()\n",
        "temp_df = random_swap_sentences_on_labels(temp_df, 1, 100)\n",
        "temp_df = random_swap_sentences_on_labels(temp_df, 1, 100)\n",
        "temp_df = random_swap_sentences_on_labels(temp_df, 1, 150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2m33dx006Ae"
      },
      "source": [
        "new_train_df = temp_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4A8ZHpeh1Wkh",
        "outputId": "a626f644-7c5d-47e5-ac77-577cd39110cb"
      },
      "source": [
        "new_train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9139</th>\n",
              "      <td>CHO's time is invaluable.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9140</th>\n",
              "      <td>Piccoli gives excellent performance full of de...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9141</th>\n",
              "      <td>The lack of note of * Corpus and its pleasant ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9142</th>\n",
              "      <td>... a wonderful, funny, funny funny funny.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9143</th>\n",
              "      <td>Appropriately carried out, Wilde's play is the...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9144 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  labels\n",
              "0     The Rock is destined to be the 21st Century 's...       3\n",
              "1     The gorgeously elaborate continuation of `` Th...       4\n",
              "2     Singer/composer Bryan Adams contributes a slew...       3\n",
              "3     You 'd think by now America would have had eno...       2\n",
              "4                  Yet the act is still charming here .       3\n",
              "...                                                 ...     ...\n",
              "9139                         CHO's time is invaluable.        4\n",
              "9140  Piccoli gives excellent performance full of de...       4\n",
              "9141  The lack of note of * Corpus and its pleasant ...       4\n",
              "9142        ... a wonderful, funny, funny funny funny.        4\n",
              "9143  Appropriately carried out, Wilde's play is the...       4\n",
              "\n",
              "[9144 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBpSm21O1j6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08383f1-1e7f-4b88-feb5-72979debd045"
      },
      "source": [
        "new_train_df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    2322\n",
              "1    2218\n",
              "2    1624\n",
              "0    1492\n",
              "4    1488\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyNy0c_t1rxL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "f9c3d399-613a-4356-aced-f7a1201a6036"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = new_train_df['labels'].value_counts(sort=False).plot(kind='bar')\n",
        "ax.set_xlabel(\"labels\")\n",
        "ax.set_ylabel(\"number of samples in training dataset\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'number of samples in training dataset')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yswWKuZAzgja"
      },
      "source": [
        "**Creating TorchDataSets**\n",
        "\n",
        "The steps includes preprocessing all the sentences and creating torchtext Dataset objects for the model to use. \n",
        "\n",
        "The following preprocessing have been performed:\n",
        "- lower case all sentences\n",
        "- remove stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIuLD-cxzUSb",
        "outputId": "d8595789-5c7e-4fb3-ec0c-b967ee8b1bec"
      },
      "source": [
        "import torch, torchtext\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 12\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6bb8cb46d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE7TTepYG2He"
      },
      "source": [
        "# The list of stop words which are to be removed from training and validation set.\n",
        "# The list is from nltk package.\n",
        "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZY7Z_pg0GPE"
      },
      "source": [
        "Sentence  = torchtext.legacy.data.Field(\n",
        "                  sequential = True,\n",
        "                  tokenize = 'spacy',\n",
        "                  batch_first =True,\n",
        "                  include_lengths=True,\n",
        "                  lower=True,\n",
        "                  stop_words=stop_words)\n",
        "\n",
        "Label     = torchtext.legacy.data.LabelField(\n",
        "                  tokenize = 'spacy',\n",
        "                  is_target = True,\n",
        "                  batch_first = True,\n",
        "                  sequential = False)\n",
        "fields = [('sentence', Sentence),('labels',Label)]\n",
        "train_example = [ torchtext.legacy.data.Example.fromlist([new_train_df.sentence[i], new_train_df.labels[i]], fields) for i in range(1, new_train_df.shape[0])]\n",
        "valid_example = [ torchtext.legacy.data.Example.fromlist([valid_df.sentence[i], valid_df.labels[i]], fields) for i in range(1, valid_df.shape[0])]\n",
        "train_dataset = torchtext.legacy.data.Dataset(train_example, fields)\n",
        "valid_dataset = torchtext.legacy.data.Dataset(valid_example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmeHSYWn3QCD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oAOXCMoIoSE"
      },
      "source": [
        "We limit the vocab to 8000 tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TQq26ZaH18K"
      },
      "source": [
        "Sentence.build_vocab(train_dataset, max_size=8000)\n",
        "Label.build_vocab(train_dataset, max_size=8000)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-lTygvRIlse",
        "outputId": "e21cb1a4-6882-4a79-d87d-e3e6c3c3a529"
      },
      "source": [
        "print('Size of input vocab : ', len(Sentence.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appeared repeatedly :', list(Sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  8002\n",
            "Size of label vocab :  5\n",
            "Top 10 words appeared repeatedly : [('.', 8595), (',', 7631), ('-', 2876), (\"'s\", 2611), ('film', 1249), ('movie', 1103), ('`', 811), ('...', 696), (\"n't\", 695), ('one', 609)]\n",
            "Labels :  defaultdict(None, {3: 0, 1: 1, 2: 2, 0: 3, 4: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMLHK1LPQCEQ"
      },
      "source": [
        "**Check the device used**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQrboZaVP-PW",
        "outputId": "38c8f363-2525-4255-f77b-adadea3db88a"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8-auIQNQFSz"
      },
      "source": [
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train_dataset, valid_dataset), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0B9nN41QHyZ"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjaHC4e-QMaU"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32s-kfIoQN0q"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Sentence.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 5\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5a49yhfQPKX",
        "outputId": "2b6f4aff-d988-4cd7-8327-b2cce411316c"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(8002, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n",
            "The model has 2,642,705 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX2FYNOjQQaB"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLfqsj2rQRxt"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        sentence, sentence_lengths = batch.sentence   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(sentence, sentence_lengths).squeeze()\n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nJ_B5mXQTIA"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            sentence, sentence_lengths = batch.sentence\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(sentence, sentence_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk6uJUBjQUV_",
        "outputId": "0d94d714-120f-422a-e26e-02915e826f7e"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.593 | Train Acc: 25.56%\n",
            "\t Val. Loss: 1.579 |  Val. Acc: 27.71% \n",
            "\n",
            "\tTrain Loss: 1.582 | Train Acc: 29.12%\n",
            "\t Val. Loss: 1.570 |  Val. Acc: 29.35% \n",
            "\n",
            "\tTrain Loss: 1.552 | Train Acc: 34.43%\n",
            "\t Val. Loss: 1.544 |  Val. Acc: 33.96% \n",
            "\n",
            "\tTrain Loss: 1.500 | Train Acc: 39.29%\n",
            "\t Val. Loss: 1.541 |  Val. Acc: 34.35% \n",
            "\n",
            "\tTrain Loss: 1.450 | Train Acc: 45.25%\n",
            "\t Val. Loss: 1.535 |  Val. Acc: 35.36% \n",
            "\n",
            "\tTrain Loss: 1.399 | Train Acc: 51.61%\n",
            "\t Val. Loss: 1.527 |  Val. Acc: 35.42% \n",
            "\n",
            "\tTrain Loss: 1.346 | Train Acc: 58.07%\n",
            "\t Val. Loss: 1.537 |  Val. Acc: 34.40% \n",
            "\n",
            "\tTrain Loss: 1.295 | Train Acc: 64.05%\n",
            "\t Val. Loss: 1.535 |  Val. Acc: 34.88% \n",
            "\n",
            "\tTrain Loss: 1.246 | Train Acc: 69.25%\n",
            "\t Val. Loss: 1.544 |  Val. Acc: 33.12% \n",
            "\n",
            "\tTrain Loss: 1.203 | Train Acc: 73.62%\n",
            "\t Val. Loss: 1.549 |  Val. Acc: 32.68% \n",
            "\n",
            "\tTrain Loss: 1.166 | Train Acc: 77.15%\n",
            "\t Val. Loss: 1.546 |  Val. Acc: 33.57% \n",
            "\n",
            "\tTrain Loss: 1.136 | Train Acc: 80.05%\n",
            "\t Val. Loss: 1.547 |  Val. Acc: 33.63% \n",
            "\n",
            "\tTrain Loss: 1.111 | Train Acc: 81.84%\n",
            "\t Val. Loss: 1.558 |  Val. Acc: 32.44% \n",
            "\n",
            "\tTrain Loss: 1.092 | Train Acc: 83.41%\n",
            "\t Val. Loss: 1.551 |  Val. Acc: 33.51% \n",
            "\n",
            "\tTrain Loss: 1.076 | Train Acc: 84.75%\n",
            "\t Val. Loss: 1.557 |  Val. Acc: 32.80% \n",
            "\n",
            "\tTrain Loss: 1.064 | Train Acc: 85.58%\n",
            "\t Val. Loss: 1.560 |  Val. Acc: 31.70% \n",
            "\n",
            "\tTrain Loss: 1.054 | Train Acc: 86.30%\n",
            "\t Val. Loss: 1.562 |  Val. Acc: 32.38% \n",
            "\n",
            "\tTrain Loss: 1.047 | Train Acc: 86.81%\n",
            "\t Val. Loss: 1.563 |  Val. Acc: 31.79% \n",
            "\n",
            "\tTrain Loss: 1.040 | Train Acc: 87.22%\n",
            "\t Val. Loss: 1.563 |  Val. Acc: 32.35% \n",
            "\n",
            "\tTrain Loss: 1.035 | Train Acc: 87.58%\n",
            "\t Val. Loss: 1.560 |  Val. Acc: 33.10% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}